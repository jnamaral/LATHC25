<html><head></head>
<body>
<center>
<h1><a href="http://www.cs.ualberta.ca/%7Eamaral/cascon/CDP06/"> 5th Workshop on Compiler-Driven Performance</a></h1>
<h2>October 16, 2006<br>
Hilton Suites Toronto/Markham Conference Centre,<br>
Markham, Ontario, Canada<br>
<br>
Associated with <a href="http://www.cas.ibm.com/cascon">CASCON 2006</a><br>
(http://www.cas.ibm.com/cascon)<br>
</h2>
</center>
<hr style="width: 100%; height: 2px;">
<center>
<h2>Final Program --- <font color="red"> Slides Now Available (see abstracts below)</font></h2><h2>
<a name="TOP"></a>
</h2></center>
<hr style="width: 100%; height: 2px;">
<b>Mini Section 1 - Chair: <a href="http://www.cs.ualberta.ca/%7Eamaral">Jos&eacute Nelson Amaral</a> - University of Alberta</b><br>
<br>
<table border="0" width="100%">
  <tbody>
    <tr>
      <td width="13%">
	09:00-09:30  
      </td>
      <td>
	<a href="#PengWu"> 
	  Efficient Loop Versioning for Relative Alignment</a> <br>
	<b>Peng Wu</b>, Peng Zhao*, Rohini Nair, and Alexander
	Eichenberger - IBM T. J. Watson Research Center, * IBM Toronto Lab
      </td>
    </tr>
    <tr>
      <td width="13%">
	09:30-10:00
      </td>
      <td>
	<a href="#KitBarton">
	  Productivity and Performance using the IBM XLUPC compiler</a></br>
	<b>Kit Barton</b>*, C&auml;lin Cas&ccedil;aval**, George Alm&aacute;si**, Philip Luk***, Raymond Mak***,
	Roch Archambault***, and Jos&eacute Nelson Amaral* - * University of Alberta, **IBM T. J. Watson Research Center, *** IBM Toronto Laboratory
      </td>
    </tr>
    <tr>
      <td width="13%">
	10:00-10:30
      </td>
      <td>
	<a href="#MarkStoodley"> Patching Code without Livelock in a Real-Time Environment</a><br>
	<b>Mark Stoodley</b> - IBM Toronto Laboratory<br>
      </td>
    </tr>
  </tbody>
</table>
<hr style="width: 100%; height: 2px;">
<table border="0" width="100%">
  <tbody>
    <tr>
      <td width="13%">
	<b>10:30-11:00</b>
      </td>
      <td>
	<b>Break</b>
      </td>
    </tr>
  </tbody>
</table>
<hr style="width: 100%; height: 2px;">
<b>Mini Section 2 - Chair: Peng Wu - IBM T. J. Watson Research Center</b><br>
<br>
<table border="0" width="100%">
  <tbody>
    <tr>
      <td width="13%">
	11:00-11:30
      </td>
      <td>
	<a href="#GhulamLashari">
	  Control Flow Virtualization for General-Purpose Computation on Graphics Hardware</a><br>
	<b>Ghulam Lashari</b> and Ond&#345;ej Lhot&aacute;k - University of Waterloo<br>
      </td>
    </tr>
    <tr>
      <td width="13%">
	11:30-12:00
      </td>
      <td>
	<a href="#StephenCurial">
	  Determining Tree-Traversals Orientation using Feedback-Directed Analysis
	</a> <br>
	<b>Stephen Curial</b>, Kevin Andrusky, and Jos&eacute Nelson Amaral - University of 
	Alberta<br>
      </td>
    </tr>
</tbody></table>
<hr style="width: 100%; height: 2px;">
<table border="0" width="100%">
  <tbody>
  <tr>
    <td width="13%">
      <b>12:00-01:00</b>
    </td>
    <td>
      <b>Lunch</b>
    </td>
  </tr>
  </tbody>
</table>
<hr style="width: 100%; height: 2px;">
<b>Mini Section 3 - Chair: Arie Tal - IBM Toronto Lab</b><br>
<br>
<table border="0" width="100%">
  <tbody>
  <tr>
    <td width="13%">
    01:00-01:30
    </td>
    <td>
      <a href="#ChrisPickett">
	Software Speculative Multithreading for Java</a><br>
      <b>Chris Pickett</b> and Clark Verbrugge - McGill University
    </td>
  </tr>
  <tr>
    <td width="13%">
    01:30-02:00
    </td>
    <td>
      <a href="#BorysBradel">Trace-based automatic parallelization in the Jikes RVM</a> <br>
      <b>Borys Bradel</b> and Tarek S. Abdelrahman - University of Toronto
    </td>
  </tr>
  <tr>
    <td width="13%">
      02:00-02:30
    </td>
    <td>
      <a href="#DavidPereira">Speculative Partial Dead Code Elimination for JIT Compilers</a><br>
      <b>David Pereira</b>  and  Nigel Horspool - University of Victoria
    </td>
  </tr>
  </tbody>
</table>
<hr style="width: 100%; height: 2px;">
<table border="0" width="100%">
  <tbody>
  <tr>
    <td width="13%">
      <b>02:30-03:00</b>
    </td>
    <td align="left">
      <b>Break</b>
    </td>
  </tr>
  </tbody>
</table>
<hr style="width: 100%; height: 2px;">
<b>Mini Section 4 - Chair: <a href="http://plg.uwaterloo.ca/~olhotak">Ond&#345;ej Lhot&aacute;k</a> - University of Waterloo</b><br>
<br>
<table border="0" width="100%">
  <tbody>
  <tr>
    <td width="13%">
      03:00-03:30
    </td>
    <td>
      <a href="#AbidMalik">
	Optimal Basic Block and Superblock Instruction Scheduling.</a><br>
      <b>Abid Malik</b> and Peter van Beek - University of Waterloo
    </td>
  </tr>
  <tr>
    <td width="13%">
      03:30-04:00
    </td>
    <td>
      <a href="#MariusPirvu"> Reducing Startup Costs of Java
	Applications with Shared Relocatable Code</a><br> 
      Derek Inglis, Marius Lut, <b>Kenneth Ma</b>, <b>Marius Pirvu</b> - IBM Toronto Laboratory
    </td>
  </tr>
  </tbody>
</table>
<hr style="width: 100%; height: 2px;">


<p><a name="PengWu"> 
<b>Efficient Loop Versioning for Relative Alignment</b><br>
      Peng Wu, Peng Zhao*, Rohini Nair, and Alexander Eichenberger, <br> 
      IBM T. J. Watson Research Center, * IBM Toronto Laboratory<br>
 <b>Presentation Slides:</b> <a href="slides/CDP06-wu.ppt">[PPT]</a>
<!-- <a href="slides/CDP05-pengWu.pdf">[PDF]</a> </b><br>
-->
</p>

<p>    
  This talk presents a novel loop versioning technique to
  specialize runtime memory alignment during SIMD code
  generation. Memory misalignment is one of the major overhead when
  vectorizing for today's SIMD architectures. For some SIMD
  architectures, such as SPE or VMX, one can always generate a
  generic permutation sequence to handle any runtime
  misalignment. However, one can significantly reduce such
  permutation overhead by specializing certain values of runtime
  misalignment. For other architectures, such as BG/L, runtime
  alignment has to be specialized into compile-time alignment to be
  simdized. This is called loop versioning for alignment. The novelty
  of our versioning technique is that we specialize on the relative
  alignment between memory streams involved in a
  computation. Compared to prior versioning schemes, our versioning
  scheme avoids generating unnecessary versions and produces
  versioning conditions that are less constrained. We will also
  present quantitative evaluation of our versioning technique on real
  benchmarks.</a></p>
</p>
<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">

<a name="KitBarton"> 
  <b>Productivity and Performance using the IBM XLUPC compiler</b><br>
  Kit Barton*, C&auml;lin Cas&ccedil;aval**, George Alm&aacute;si**, Philip Luk***, Raymond Mak***,
  Roch Archambault***, and Jos&eacute Nelson Amaral* - * University of Alberta, **IBM T. J. Watson Research Center, *** IBM Toronto Laboratory<br>
  <b>Presentation Slides:</b> </b><a href="slides/CDP06-barton.ppt">[PPT]</a>
<!-- <a href="slides/CDP06-KitBarton.pdf">[PDF]</a> </b><br>
    -->

<p>
  Unified Parallel C (UPC) is an emerging Partitioned Global Address
  Space (PGAS) language that extends the familiar C language with
  shared-memory abstractions for explicit parallel programming. This
  presentation discusses our experience in implementing the UPC
  language within the IBM XL compiler framework, and a set of compiler
  optimizations that are crucial for the performance and scalability
  of UPC codes. We show how these optimizations allows scaling of HPC
  Challenge benchmarks to unprecedented levels for shared memory
  programs -- 131072 threads on the Blue Gene/L machine. We conclude
  by presenting future research directions that will explore using
  PGAS languages (UPC in particular) as a unique programming model for
  a variety of parallel architectures.
</p>                                                   
<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">

<a name="MarkStoodley"> 
  <b> Patching Code without Livelock in a Real-Time Environment</b><br>
  Mark Stoodley - IBM Toronto Laboratory<br>
  <b>Presentation Slides:</b> <a href="slides/CDP06-stoodley.ppt">[PPT]</a>
 <!-- <a href="slides/CDP06-MarkStoodley.pdf">[PDF]</a> </b><br>
    -->

<p>
Modern virtual machines employ self-modifying code, or code patching, in a
variety of different circumstances: to create efficient access to variables
that are unresolved when code is compiled, to fill in caches for virtual
and interface invocations, and to update invocations when the target is
(re)compiled.  To improve the efficiency of code patching in a
multi-threaded environment, operating system locks are generally avoided
and techniques that involve spin loops or busy-wait loops are often used
instead. Such techniques are perfectly acceptable when the scheduling
policy of the underlying operating system is round-robin based.  Real-time
operating systems, however, typically employ a FIFO scheduling policy for
real-time threads to provide more strict guarantees of deterministic
performance for applications enlisting multiple threads with different
priorities.  In such an environment, traditional code patching techniques
open the door to live lock where all threads are active but not making any
progress.  A low priority thread selected to perform a particular code
patching operation may be pre-empted by a higher priority thread before
completing the patch.  If the high priority thread then reaches the point
requiring the patch, that thread will enter the spin loop used to prevent
multiple threads from corrupting the patching operation.  The higher
priority thread will never exit the spin loop because the low priority
thread cannot be scheduled to complete the patching operation.
</p>
<p>
In this talk, I describe how the many runtime functions that implement
code patching within the Testarossa JIT were modified to avoid this
live-lock problem in the IBM WebSphere Real Time product.  A detailed
example will demonstrate both the problem and its solution, as well as
some of the implementation-level issues that complicate getting it all
right.
</p>
  <a href="#TOP"> Back to CDP06 Program</a>
  <hr style="width: 100%; height: 2px;">

  <a name="GhulamLashari"> 
    <b>	  Control Flow Virtualization for General-Purpose Computation on Graphics Hardware</b><br>
    Ghulam Lashari and Ond&#345;ej Lhot&aacute;k - University of Waterloo<br>
<b>Presentation Slides:</b> <a href="slides/CDP06-lashari.ppt">[PPT]</a>
<!--
<a href="slides/CDP06-GhulamLashari.pdf">[PDF]</a> </b><br>
-->
<p>
    Graphics hardware (GPUs) have become fully programmable in the
    last few years, and have more computational power and memory
    bandwidth than traditional microprocessors (CPUs). However, GPUs
    have hard limits on various resources, making general-purpose
    computation on GPUs (GPGPU) difficult to implement. We focus on
    overcoming limits on control flow constructs. Current GPUs have
    either no control flow, or tight limits on loop nesting depth and
    iteration count. We present control flow virtualization techniques
    that allow a program with arbitrary control flow to be executed on
    a GPU by either partitioning the program into passes and
    performing the control flow on the CPU, or by restructuring the
    program to fit the control flow limits of the GPU. Along with
    virtualization of other GPU resources, our approach enables
    efficient execution of a large class of data parallel problems on
    GPUs.
</p>
<br>


<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">

<a name="StephenCurial"> 
  <b>	  Determining Tree-Traversals Orientation using Feedback-Directed Analysis
  </b> <br>
  Stephen Curial, Kevin Andrusky, and Jos&acute Nelson Amaral - University of 
  Alberta<br>
<b>Presentation Slides:</b> <a href="slides/CDP06-curial.ppt">[PPT]</a>
<!--
<a href="slides/CDP06-StephenCurial.pdf">[PDF]</a> </b><br>
-->
<p>
    The memory wall significantly impedes the performance of many
    applications that use pointer-based tree data structures. If
    optimizing compilers were able to determine the orientation of tree
    traversals, they could improve the data layout resulting in
    improved cache performance. We developed a framework that
    automatically instruments an application containing pointer-based
    trees with calls to our Tree Analysis Library (TAL) to determine if
    the traversal follows a breadth-first orientation, depth-first
    orientation, or neither.  The instrumented application can be
    executed offline to determine the predominant traversal orientation
    for each disjoint tree data structure. We implemented our
    tree-traversal orientation analysis in the Open Research Compiler
    and ran tests on our own benchmarks and the Olden benchmark
    suite. Finally, we discuss potential clients of this analysis and
    how they could improve program performance.
</p>
<br>


<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">

<a name="ChrisPickett"> 
  <b>	Software Speculative Multithreading for Java</b><br>
  Chris Pickett and Clark Verbrugge - McGill University<br>
  <b>Presentation Slides:</b>
<!-- <a href="slides/CDP06-ChrisPickett.ppt">[PPT]</a>
-->
<a href="slides/CDP06-pickett.pdf">[PDF]</a> </b><br>

<p>
    Speculative multithreading (SpMT) is a dynamic parallelization
    technique that depends on out-of-order execution to achieve
    speedup.  SableSpMT is our software implementation of SpMT inside
    the SableVM Java virtual machine, and it runs on commodity
    multiprocessors.  In this talk we describe various SpMT support
    components, namely thread forking and joining, dependence
    buffering, stack buffering, and return value prediction.  We also
    consider the interaction of speculation with Java language
    features, namely garbage collection, native methods, exceptions,
    synchronization, the Java memory model, and each individual
    bytecode instruction.  As an analysis framework, SableSpMT is able
    to provide profiling information, adapt to runtime feedback, and
    exploit static analysis results; we can also use it to demonstrate
    relative performance gains in the absence of overhead.  Finally,
    we present our initial work on libspmt, a VM- and
    language-agnostic C library for speculative multithreading.
</p>

<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">

<a name="BorysBradel">


<b>Trace-based automatic parallelization in the Jikes RVM</b><br>
Borys Bradel and Tarek S. Abdelrahman - University of Toronto<br>
<b>Presentation Slides:</b> <a href="slides/CDP06-bradel.ppt">[PPT]</a>
<!-- <a href="slides/CDP06-BorysBradel.pdf">[PDF]</a> </b><br>
-->

<p>
The processor industry is moving towards systems that contain multiple
processors.  However, most software is designed to use a single processor.
Writing parallel multi-threaded software, although possible, is difficult
and time consuming.  An alternative is to write sequential software, and
then automatically parallelizing it.  We examine one possible approach to
performing automatic parallelization: divide a program into traces and
execute these traces in parallel.  Several benefits of using traces are
that source code is not required, that they are easy to identify, and that
the granularity of parallelism is not fixed.
</p>
<p>
We have created an infrastructure in the Jikes RVM.  The infrastructure
identifies which part of a method that is being compiled contains traces,
separates that part, and transforms it so that it can execute in parallel.
Our infrastructure consists of a pass in the optimizing compiler, a
trampoline, and a parallel driver.  We use the Java Grande benchmarks to
evaluate our work.  We examine the overhead and effectiveness of our
infrastructure, and we identify a number of challenges associated with
automatic parallelization.
</p>


<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">


<a name="DavidPereira"> 
<b>Speculative Partial Dead Code Elimination for JIT Compilers</b><br>
    David Pereira  and  Nigel Horspool ---  University of Victoria<br>
<b>Presentation Slides:</b>
<!--
<a href="slides/CDP06-DavidPereira.ppt">[PPT]</a>
-->
<a href="slides/CDP06-peeira.pdf">[PDF]</a> </b><br>
<p>
    Partial dead code elimination is a compiler optimization which
    avoids computing an expression unless the result is used on all
    subsequent execution paths.  In this talk, we describe an elegant
    new approach that uses program profile information to select the
    most profitable places to apply the optimization.  This approach
    is based on dividing the program into hot and cold regions, and is
    efficient enough for use in just-in-time compilers.  Our algorithm
    lends itself easily to adaptation for the Java programming
    language, where run-time program safety (via checks) and precise
    exception semantics must be guaranteed.
</p>

<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">

<a name="AbidMalik"> 
  <b>	Optimal Basic Block and Superblock Instruction Scheduling.</b><br>
  Abid Malik and Peter van Beek - University of Waterloo<br>

<b>Presentation Slides:</b> <a href="slides/CDP06-malik.ppt">[PPT]</a>
<!-- <a href="slides/CDP06-AbidMalik.pdf">[PDF]</a> </b><br>
-->
<p>
    Instruction scheduling is one of the most important steps for
    improving the performance of object code produced by a
    compiler. Two fundamental problems that arise in instruction
    scheduling are to find a minimum length schedule for a basic block
    and a minimum expected length schedule for a superblock, subject
    to precedence, latency, and resource constraints. Solving these
    problems exactly is NP-complete, and heuristic approaches are
    currently used in most compilers.  In contrast, we present a
    scheduler that finds provably <i> optimal</i> schedules for basic
    blocks and super blocks using techniques from constraint
    programming.  We experimentally evaluated our optimal scheduler on
    the SPEC 2000 integer and floating point benchmarks.  On this
    benchmark suite, the optimal scheduler was very robust---all but a
    handful of the hundreds of thousands of blocks in our benchmark
    suite were solved optimally within a reasonable time limit---and
    scaled to the largest blocks, including blocks with up to 2600
    instructions.  This compares favorably to the best previous exact
    approaches.

<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">

<a name="MariusPirvu"> 
  <b>Reducing Startup Costs of Java
    Applications with Shared Relocatable Code</b><br> 
  Derek Inglis, Marius Lut, Kenneth Ma, Marius Pirvu - IBM Toronto Laboratory
  <br>
<p>
    Thanks to recent advances in Just-In-Time (JIT) compilation
    technology, the performance of Java applications approaches, and
    sometimes exceeds, that of statically compiled
    programs. Unfortunately, Java applications are still prone to being
    sluggish during their incipient phases for two reasons: (1) methods
    start by being interpreted and (2) the bulk of dynamic
    compilations, with their inherent overhead, happens during
    startup. Many application classes are affected. For instance, short
    running applications perform poorly because their startup overheads
    cannot be amortized. Interactive applications may exhibit a large
    response time. Applications used in the software development cycle,
    which need to be restarted many times a day, become annoying if
    they take too much time to load. Finally, important Java servers
    deployed in a production environment, such as WebSphere, should
    ideally ramp-up fast to optimal throughput and recover fast after a
    scheduled or unforeseen downtime.
</p>
<p>
    The J9 JVM from IBM employs different mechanisms for reducing the
    startup overhead: asynchronous compilation, lowering the level of
    JIT optimizations during the phases with high class loading
    activity or caching the bytecodes of loaded classes. We will
    briefly describe these existing techniques and show their impact on
    the startup time of WebSphere Application Server 6.02/6.1. While
    effective, the aforementioned solutions are not enough. Due to the
    constant need of better and better runtime performance, the JIT
    compiler becomes increasingly complex. This added complexity
    translates more often than not into higher compilation time and
    thus higher startup costs.
</p>
<p>
    To restore the balance between runtime performance and startup time
    we have devised a new technique, called shared relocatable code,
    that will be implemented in the upcoming J9 SDK 1.6. The basic idea
    is to store the compiled code of a method in shared memory, in a
    relocatable format. Subsequent JVM invocations can avoid the
    overhead of compilation by taking the available code from shared
    memory and relocating it in their own memory space.
</p>
<p>
    While the concept appears simple at first glance, there are many
    hurdles that need to be overcome. The quality of the relocatable
    code may be poor due to several factors: (1) most of the symbols
    need to be treated as unresolved; (2) inlining opportunities are
    very limited; (3) we cannot take advantage of the optimizations
    based on class hierarchy. Code quality is a thorny issue because
    improving startup of an application like WebSphere at the expense
    of runtime performance is not acceptable. To minimize the runtime
    performance degradation we have to devise effective heuristics that
    dictate when to generate relocatable code and when to use it. We
    will describe such heuristics, present experimental data showing
    their efficiency, and discuss the tradeoffs involved. Our current
    prototype is able to achieve significant startup time benefits:
    16% for WebSphere, 11% for Eclipse, 57% for Tomcat  while
    maintaining a very good throughput for an application
    server. Furthermore, users that are billed based on the machine's
    resources they consume will also be satisfied by the savings in CPU
    utilization.
</p>
<!-- <b>Presentation Slides:</b> <a href="slides/CDP06-MariusPirvu.ppt">[PPT]</a> <a href="slides/CDP06-MariusPirvu.pdf">[PDF]</a> </b><br>
-->

<a href="#TOP"> Back to CDP06 Program</a>
<hr style="width: 100%; height: 2px;">

</body>
